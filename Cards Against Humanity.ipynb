{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando bibliotecas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importamos las bibliotecas necesarias para que funcione el notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "import nltk\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "from sklearn import decomposition\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "from random import choice\n",
    "from operator import itemgetter\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación del dataframe de las cartas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el dataframe de las cartas del juego a partir del archivo 'cards.json'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "#Carga del json\n",
    "with open('cards.json') as f:\n",
    "    dictionary = json.load(f)\n",
    "#Creamos un dataframe que contenga todas las cartas\n",
    "black_cards = DataFrame.from_dict(dictionary['blackCards'])\n",
    "white_cards = DataFrame.from_dict(dictionary['whiteCards'])\n",
    "black_cards['type'] = ['prompt' for i in range(len(black_cards))]\n",
    "black_cards['tags'] = [[] for i in range(len(black_cards))]\n",
    "white_cards['type'] = ['response' for i in range(len(white_cards))]\n",
    "black_cards = black_cards[['text','type','tags']]\n",
    "white_cards = white_cards[['text','type','tags']]\n",
    "cards = black_cards.append(white_cards, sort = False)\n",
    "cards = cards.reset_index(drop = True)\n",
    "cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carga de vectores Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los vectores word2vec, cada palabra es representada por un vector de 50 dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('card_vectors.json') as f:\n",
    "    word_vectors = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de vectores promedio para cada carta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que crea un vector promedio para cada carta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un vector promedio para cada carta omitiendo las palabras que no nos otorgan ningún tipo de información (stopwords). En el caso de las cartas blancas, también promediamos los vectores correspondientes a sus etiquetas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen tres tipos de vectores promedio: 'AverageVector', 'NNVBVector' y 'WeightedAvgVector'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "#vector_type: tipo de vector\n",
    "#cards: dataframe de las cartas\n",
    "def vectors(vector_type, cards):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    #Diccionario con listas de vectores y lista con vectores promedio para el dataframe\n",
    "    c_vectors, values = {}, []\n",
    "    for i in cards.index.values:\n",
    "        text = str(cards['text'].loc[i].encode('utf8'))\n",
    "        c_vectors[i] = []\n",
    "        for word in tokenizer.tokenize(text):\n",
    "            #Omitimos las stop words y nos aseguramos que este en nuestros vectores word2vec\n",
    "            if word.lower() in word_vectors.keys() and word.lower() not in stopwords.words('english'):\n",
    "                if vector_type == 'AverageVector':\n",
    "                    c_vectors[i].append(np.array(word_vectors[word.lower()]))\n",
    "                elif vector_type == 'NNVBVector':\n",
    "                    if nltk.pos_tag(word.lower())[0][1] == 'VB' or nltk.pos_tag(word.lower())[0][1] == 'NN':\n",
    "                        c_vectors[i].append(np.array(word_vectors[word.lower()]))\n",
    "                else:\n",
    "                    if nltk.pos_tag(word.lower())[0][1] == 'VB' or nltk.pos_tag(word.lower())[0][1] == 'NN':\n",
    "                        c_vectors[i].append(np.array(word_vectors[word.lower()]) * 1.5)\n",
    "                    else:\n",
    "                        c_vectors[i].append(np.array(word_vectors[word.lower()]))\n",
    "        #Agregamos los vectores de las etiquetas\n",
    "        if cards['tags'].loc[i] != []:\n",
    "            for word in cards['tags'].loc[i]:\n",
    "                if word.lower() in word_vectors.keys() and word.lower() not in stopwords.words('english'):\n",
    "                    if vector_type == 'WeightedAvgVector':\n",
    "                        c_vectors[i].append(np.array(word_vectors[word.lower()]) * 1.5)\n",
    "                    else:\n",
    "                        c_vectors[i].append(np.array(word_vectors[word.lower()]))\n",
    "    #Sumamos los vectores y calculamos el promedio de estos\n",
    "    for i in cards.index.values:\n",
    "        sum_arr = np.zeros(50)\n",
    "        for arr in c_vectors[i]:\n",
    "            sum_arr += arr\n",
    "        if len(c_vectors[i]) == 0:\n",
    "            n = 1\n",
    "        else:\n",
    "            n = len(c_vectors[i])\n",
    "        avg_arr = []\n",
    "        for s in sum_arr:\n",
    "            avg_arr.append(s/n)\n",
    "        values.append(np.array(avg_arr))\n",
    "    #Creamos la nueva columna\n",
    "    cards[vector_type] = values\n",
    "    return cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de vectores promedio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un vector promedio para cada carta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = vectors('AverageVector', cards)\n",
    "cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de vectores promedio utilizando solamente verbos y sustantivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos otro vector promedio para cada carta tomando en cuenta solamente verbos y sustantivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = vectors('NNVBVector', cards)\n",
    "cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de vectores promedio con pesos de 150% para verbos y sustantivos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos un último vector promedio para cada carta dándole un peso de 150% a los verbos y sustantivos. En el caso de las cartas blancas, este peso también se ve reflejado en sus etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = vectors('WeightedAvgVector', cards)\n",
    "cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizando las etiquetas de las tarjetas blancas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos un análisis simple de las etiquetas que tienen las cartas blancas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = []\n",
    "for i in range(len(cards)):\n",
    "    for tag in cards.loc[i]['tags']:\n",
    "        all_tags.append(tag)\n",
    "Series(all_tags).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de una lista de arreglos para graficación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos los vectores promedio de las cartas blancas y negras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectores de cartas negras\n",
    "prompt_vecs = []\n",
    "for arr in cards[cards['type'] == 'prompt']['WeightedAvgVector'].values:\n",
    "    prompt_vecs.append(arr)\n",
    "#Vectores de cartas blancas\n",
    "response_vecs = []\n",
    "for arr in cards[cards['type'] == 'response']['WeightedAvgVector'].values:\n",
    "    response_vecs.append(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilización de PCA para reducir dimensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función para reducir la dimensionalidad de los vectores utilizando PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toma una serie de vectores y reduce su dimensionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectors: vectores de entrada\n",
    "#num: número de dimensiones a reducir\n",
    "def PCA(vectors, num):\n",
    "    pca = decomposition.PCA(n_components = num)\n",
    "    pca.fit(vectors)\n",
    "    reduced_vectors = pca.transform(vectors)\n",
    "    return (reduced_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficación en 3 y 2 dimensiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducimos la dimensionalidad de los vectores y los graficamos en 2 y 3 dimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasamos de 50 dimensiones a 3\n",
    "prompt_vecs3 = PCA(prompt_vecs, 3)\n",
    "response_vecs3 = PCA(response_vecs, 3)\n",
    "#Pasamos de 50 dimensiones a 2\n",
    "prompt_vecs2 = PCA(prompt_vecs, 2)\n",
    "response_vecs2 = PCA(response_vecs, 2)\n",
    "#Creación de figura\n",
    "fig = plt.figure(figsize = [20,10])\n",
    "ax3 = fig.add_subplot(121, projection='3d')\n",
    "ax2 = fig.add_subplot(122)\n",
    "#Colocamos los puntos en el espacio y les damos formato\n",
    "for point in prompt_vecs3:\n",
    "    ax3.scatter(point[0], point[1], point[2], s=10, c='r', marker='x')\n",
    "for point in response_vecs3:\n",
    "    ax3.scatter(point[0], point[1], point[2], s=10, c='c', marker='o')\n",
    "for point in prompt_vecs2:\n",
    "    ax2.scatter(point[0], point[1], s=10, c='r', marker='x')\n",
    "for point in response_vecs2:\n",
    "    ax2.scatter(point[0], point[1], s=10, c='c', marker='o')\n",
    "#Etiquetas de los ejes\n",
    "ax3.set_xlabel('X')\n",
    "ax3.set_ylabel('Y')\n",
    "ax3.set_zlabel('Z')\n",
    "ax2.set_xlabel('X')\n",
    "ax2.set_ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusterización con K-Medias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos K-Medias para realizar un clustering de los vectores de las cartas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering para graficar\n",
    "#Datos para graficar\n",
    "plot_data = cards[['text','type','WeightedAvgVector']]\n",
    "#Obtenemos los vectores con pesos\n",
    "X = plot_data['WeightedAvgVector'].values.tolist()\n",
    "kmeans = KMeans(n_clusters = 15, random_state = 0, n_init = 100, max_iter = 500).fit_predict(X)\n",
    "plot_data['cluster'] = kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando coordenadas para T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De nuevo reducimos dimensionalidad, ahora utilizando T-SNE y generamos las coordenadas para su posterior graficación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtenemos los vectores con pesos\n",
    "X = plot_data['WeightedAvgVector'].values.tolist()\n",
    "print('Training TSNE model...')\n",
    "model = TSNE(n_components = 2, random_state = 0, perplexity = 15)\n",
    "coords = model.fit_transform(X)\n",
    "x_coords = [coord[0] for coord in coords]\n",
    "y_coords = [coord[1] for coord in coords]\n",
    "#Coordenadas\n",
    "plot_data['TSNE_X'] = x_coords\n",
    "plot_data['TSNE_Y'] = y_coords\n",
    "print('Done.')\n",
    "x_max = plot_data['TSNE_X'].max()\n",
    "y_max = plot_data['TSNE_Y'].max()\n",
    "x_min = plot_data['TSNE_X'].min()\n",
    "y_min = plot_data['TSNE_Y'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficación de T-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficación de los vectores en dos dimensiones, utilizando Bokeh. Agregamos etiquetas y colores distintos a cada cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.plotting import *\n",
    "from bokeh.models import *\n",
    "palette = ['#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c', '#98df8a', '#d62728', '#ff9896', '#9467bd', '#c5b0d5',\n",
    "           '#8c564b', '#c49c94', '#e377c2', '#f7b6d2', '#7f7f7f', '#c7c7c7', '#bcbd22', '#dbdb8d', '#17becf', \n",
    "           '#9edae5']\n",
    "cluster_colors = [palette[i] for i in range(10)]\n",
    "hover = HoverTool(\n",
    "    tooltips = [\n",
    "        ('text', '@desc'),\n",
    "        ('Q/A', '@qa')\n",
    "    ]\n",
    ")\n",
    "tools = [hover, PanTool(), ResetTool()]\n",
    "output_file('CAH_TSNE.html')\n",
    "p = figure(plot_width = 1000, plot_height = 1000, tools = tools, title = 'CAH Cards',\n",
    "           x_range = (x_min-1,x_max+1), y_range = (y_min-1,y_max+1))\n",
    "plot_data.sort_values(by = 'cluster', inplace = True)\n",
    "indices = plot_data.index.tolist()\n",
    "print('Building plot...')\n",
    "num_plotted = 0\n",
    "for i in range(15):\n",
    "    print('Cluster: {}'.format(i))\n",
    "    prompt_x_list = []\n",
    "    prompt_y_list = []\n",
    "    resp_x_list = []\n",
    "    resp_y_list = []\n",
    "    prompt_desc_list = []\n",
    "    resp_desc_list = []\n",
    "    p_QA_list = []\n",
    "    r_QA_list = []\n",
    "    while len(indices) > 0 and plot_data.loc[indices[0]]['cluster'] == i:\n",
    "        r = indices[0]\n",
    "        if plot_data.loc[r]['type'] == 'prompt':\n",
    "            prompt_x_list.append(plot_data.loc[r]['TSNE_X'])\n",
    "            prompt_y_list.append(plot_data.loc[r]['TSNE_Y'])\n",
    "            prompt_desc_list.append(plot_data.loc[r]['text'])\n",
    "            p_QA_list.append('Prompt')\n",
    "        else:\n",
    "            resp_x_list.append(plot_data.loc[r]['TSNE_X'])\n",
    "            resp_y_list.append(plot_data.loc[r]['TSNE_Y'])\n",
    "            resp_desc_list.append(plot_data.loc[r]['text'])\n",
    "            r_QA_list.append('Response')\n",
    "        indices.pop(0)\n",
    "        num_plotted +=1\n",
    "    p_source = ColumnDataSource(\n",
    "        data = dict(\n",
    "            x = prompt_x_list,\n",
    "            y = prompt_y_list,\n",
    "            desc = prompt_desc_list,\n",
    "            qa = p_QA_list\n",
    "        )\n",
    "    )\n",
    "    r_source = ColumnDataSource(\n",
    "        data = dict(\n",
    "            x = resp_x_list,\n",
    "            y = resp_y_list,\n",
    "            desc = resp_desc_list,\n",
    "            qa = r_QA_list\n",
    "        )\n",
    "    )\n",
    "    p.triangle('x', 'y', size = 20, source = p_source, color = palette[i], alpha = .8)\n",
    "    p.circle('x', 'y', size = 10, source = r_source, color = palette[i], alpha = .4)\n",
    "    print('Row: {}'.format(num_plotted))\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Cuáles son las mejores respuestas? (Distancia euclidiana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que obtiene las mejores cartas blancas para cada carta negra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula la distancia euclidiana entre los vectores, en este caso, entre menor sea la distancia entre dos vectores, mayor es su relación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cards: dataframe de las cartas\n",
    "#vector_type: tipo de vector\n",
    "#num: número de cartas blancas a generar\n",
    "def best_response_euclidian(cards, vector_type, num):\n",
    "    df = DataFrame(columns = ['black card'] + [str(i) for i in range(1,num + 1)])\n",
    "    for i in cards[cards['type'] == 'prompt'].index.values:\n",
    "        prompt = cards.iloc[i]\n",
    "        #Vector de carta negra\n",
    "        prompt_vec = prompt[vector_type]\n",
    "        response_distances, aux_row = [], [prompt['text']]\n",
    "        for j in cards[cards['type'] == 'response'].index.values:\n",
    "            response = cards.iloc[j]\n",
    "            #Vector de carta blanca\n",
    "            response_vec = response[vector_type]\n",
    "            #Distancia euclidiana (Norma de la resta)\n",
    "            distance = abs(LA.norm(prompt_vec - response_vec))\n",
    "            response_distances.append([distance, j])\n",
    "        #Ordenamos respecto a las distancias\n",
    "        response_distances = sorted(response_distances, key = itemgetter(0))\n",
    "        #Recortamos la lista, solo tomamos los elementos que nos interesan\n",
    "        response_distances = response_distances[0:num]\n",
    "        for d in response_distances:\n",
    "            aux_row.append(cards.iloc[d[1]]['text'])\n",
    "        df_aux = DataFrame([aux_row], columns = ['black card'] + [str(i) for i in range(1,num + 1)])\n",
    "        df = df.append(df_aux, ignore_index = True)\n",
    "    df = df.reset_index(drop = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejores respuestas (Vector promedio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidian_average = best_response_euclidian(cards, 'AverageVector', 3)\n",
    "euclidian_average.loc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejores respuestas (Solamente verbos y sustantivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "euclidian_nnvb = best_response_euclidian(cards, 'NNVBVector', 3)\n",
    "euclidian_nnvb.loc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejores respuestas (Verbos y sustantivos con 150% peso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidian_wv = best_response_euclidian(cards, 'WeightedAvgVector', 3)\n",
    "euclidian_wv.loc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Cuáles son las mejores respuestas? (Simulitud de coseno)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que obtiene las mejores cartas blancas para cada carta negra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula la similitud de coseno entre los vectores, en este caso, entre mayor sea el coseno entre dos vectores, mayor es la relación que existe entre ambos, es decir, el ángulo formado entre los dos vectores es cercano a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cards: dataframe de las cartas\n",
    "#vector_type: tipo de vector\n",
    "#num: número de cartas blancas a generar\n",
    "#sim: valor de similitud de coseno (por defecto 1)\n",
    "def best_response_cosine_similarity(cards, vector_type, num, sim = 1):\n",
    "    df = DataFrame(columns = ['black card'] + [str(i) for i in range(1,num + 1)])\n",
    "    for i in cards[cards['type'] == 'prompt'].index.values:\n",
    "        prompt = cards.iloc[i]\n",
    "        #Vector de carta negra\n",
    "        prompt_vec = prompt[vector_type]\n",
    "        response_similarities, aux_row = [], [prompt['text']]\n",
    "        for j in cards[cards['type'] == 'response'].index.values:\n",
    "            response = cards.iloc[j]\n",
    "            #Vector de carta blanca\n",
    "            response_vec = response[vector_type]\n",
    "            #Producto punto entre el producto de las normas\n",
    "            similarity = np.dot(prompt_vec, response_vec) / (LA.norm(prompt_vec) * LA.norm(response_vec))\n",
    "            if sim == 0:\n",
    "                similarity = abs(sim - similarity)\n",
    "            else:\n",
    "                similarity = abs((sim - similarity)/sim)\n",
    "            response_similarities.append([similarity, j])\n",
    "        #Ordenamos respecto a la similitud de coseno\n",
    "        response_similarities = sorted(response_similarities, key = itemgetter(0))\n",
    "        #Recortamos la lista, solo tomamos los elementos que necesitamos\n",
    "        response_similarities = response_similarities[0:num]\n",
    "        for s in response_similarities:\n",
    "            aux_row.append(cards.iloc[s[1]]['text'])\n",
    "        df_aux = DataFrame([aux_row], columns = ['black card'] + [str(i) for i in range(1,num + 1)])\n",
    "        df = df.append(df_aux, ignore_index = True)\n",
    "    df = df.reset_index(drop = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejores respuestas (Vector promedio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_average = best_response_cosine_similarity(cards, 'AverageVector', 3)\n",
    "cosine_average.loc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejores respuestas (Solamente verbos y sustantivos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_nnvb = best_response_cosine_similarity(cards, 'NNVBVector', 3)\n",
    "cosine_nnvb.loc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejores respuestas (Verbos y sustantivos con 150% peso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_wv = best_response_cosine_similarity(cards, 'WeightedAvgVector', 3)\n",
    "cosine_wv.loc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustándose al usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que 'ajusta' la máquina al humor del usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genera una similitud de coseno promedio que se ajusta a tus elecciones. El humor es subjetivo y cada persona tiene su propia visión de este, por lo que ajustar la computadora a tu comportamiento puede dar mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cards: dataframe de las cartas\n",
    "#vector_type: tipo de vector\n",
    "#num_r: número de rondas a jugar\n",
    "import time\n",
    "def train_ia(cards, vector_type, num_r):\n",
    "    avg_user = []\n",
    "    for t in range(num_r):\n",
    "        clear_output()\n",
    "        white_cards_user = []\n",
    "        #Carta negra random\n",
    "        r = choice(cards[cards['type'] == 'prompt'].index.values.tolist())\n",
    "        black_card = cards.iloc[r]\n",
    "        c = black_card['text'].count('_')\n",
    "        if c == 0:\n",
    "            c = 1\n",
    "        prompt_vec = black_card[vector_type]\n",
    "        #5 cartas blancas random\n",
    "        for i in range(10):\n",
    "            n = choice(cards[cards['type'] == 'response'].index.values.tolist())\n",
    "            #Cartas blancas para el usuario\n",
    "            response = cards.iloc[n]\n",
    "            response_vec = response[vector_type]\n",
    "            similarity = np.dot(prompt_vec, response_vec) / (LA.norm(prompt_vec) * LA.norm(response_vec))\n",
    "            white_cards_user.append([response['text'], similarity])\n",
    "        print('Round {}'.format(t + 1))\n",
    "        print('Black Card\\n{}'.format(black_card['text']))\n",
    "        print('White Cards:')\n",
    "        for w in range(len(white_cards_user)):\n",
    "            print('{}. {}'.format(w + 1, white_cards_user[w][0]))\n",
    "        e = input('Choose {} White Cards: (Ej. 1 2 3): '.format(c))\n",
    "        e = e.split(' ')\n",
    "        print('Your choices:')\n",
    "        for w in e:\n",
    "            print(white_cards_user[int(w) - 1][0])\n",
    "        print('Round finished\\n')\n",
    "        a = 0\n",
    "        for j in range(c):\n",
    "            a += white_cards_user[int(e[j]) - 1][1]\n",
    "        avg_user.append(1/(a/c))\n",
    "        time.sleep(3)\n",
    "    #Media ármonica\n",
    "    return num_r/sum(avg_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_user = train_ia(cards, 'WeightedAvgVector', 15)\n",
    "sim_user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejores respuestas ajustadas al usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_user = best_response_cosine_similarity(cards, 'WeightedAvgVector', 3, sim_user)\n",
    "best_user.loc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La computadora versus el usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que simula rondas del juego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una carta negra es desplegada y tanto el usuario como la computadora deben elegir las mejores cartas blancas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cards: dataframe de las cartas\n",
    "#vector_type: tipo de vector\n",
    "#num_r: Número de rondas a jugar\n",
    "#mode: modo de juego ('Different' para que la IA y el usuario tengan diferentes cartas, 'Equal' para que tengan las\n",
    "#mismas cartas)\n",
    "#sim: similitud de coseno a comparar (por defecto 1)\n",
    "import time\n",
    "def cah(cards, vector_type, num_r, mode, sim = 1):\n",
    "    for t in range(num_r):\n",
    "        clear_output()\n",
    "        white_cards_ia, white_cards_user = [], []\n",
    "        #Carta negra random\n",
    "        r = choice(cards[cards['type'] == 'prompt'].index.values.tolist())\n",
    "        black_card = cards.iloc[r]\n",
    "        c = black_card['text'].count('_')\n",
    "        if c == 0:\n",
    "            c = 1\n",
    "        prompt_vec = black_card[vector_type]\n",
    "        #10 cartas blancas random\n",
    "        for i in range(10):\n",
    "            n = choice(cards[cards['type'] == 'response'].index.values.tolist())\n",
    "            #Cartas blancas de la IA\n",
    "            response = cards.iloc[n]\n",
    "            response_vec = response[vector_type]\n",
    "            similarity = np.dot(prompt_vec, response_vec) / (LA.norm(prompt_vec) * LA.norm(response_vec))\n",
    "            if sim == 0:\n",
    "                similarity = abs(sim - similarity)\n",
    "            else:\n",
    "                similarity = abs((sim - similarity)/sim)\n",
    "            white_cards_ia.append([response['text'], similarity])\n",
    "            if mode == 'Different':\n",
    "                #Cartas blancas para el usuario\n",
    "                m = choice(cards[cards['type'] == 'response'].index.values.tolist())\n",
    "                response = cards.iloc[m]\n",
    "                response_vec = response[vector_type]\n",
    "                similarity = np.dot(prompt_vec, response_vec) / (LA.norm(prompt_vec) * LA.norm(response_vec))\n",
    "                if sim == 0:\n",
    "                    similarity = abs(sim - similarity)\n",
    "                else:\n",
    "                    similarity = abs((sim - similarity)/sim)\n",
    "            white_cards_user.append([response['text'], similarity])\n",
    "        white_cards_ia = sorted(white_cards_ia, key = itemgetter(1))\n",
    "        #IA elige sus cartas blancas para completar la carta negra\n",
    "        white_cards_ia = white_cards_ia[0:c]\n",
    "        print('Round {}'.format(t + 1))\n",
    "        print('Black Card\\n{}'.format(black_card['text']))\n",
    "        print('White Cards:')\n",
    "        for w in range(len(white_cards_user)):\n",
    "            print('{}. {}'.format(w + 1, white_cards_user[w][0]))\n",
    "        e = input('Choose {} White Cards (Ej. 1 2 3): '.format(c))\n",
    "        e = e.split(' ')\n",
    "        print('Your choices:')\n",
    "        for w in e:\n",
    "            print(white_cards_user[int(w) - 1][0])\n",
    "        print('IA choices:')\n",
    "        for w in white_cards_ia:\n",
    "            print(w[0])\n",
    "        print('Round finished\\n')\n",
    "        time.sleep(7)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La computadora con las mismas cartas del usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cah(cards, 'WeightedAvgVector', 10, 'Equal', sim_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La computadora y el usuario con cartas distintas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cah(cards, 'WeightedAvgVector', 10, 'Different', sim_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La computadora y el usuario con las mismas cartas (el coseno de 90 grados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No está de más experimentar. Para el humor, la respuesta no debe ser 100% literal, sino que debe tener un componente de sorpresa. ¿Y si tomamos el vector \"más perpendicular\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cah(cards, 'WeightedAvgVector', 10, 'Equal', 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La computadora y el usuario con cartas distintas (vectores paralelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cah(cards, 'WeightedAvgVector', 10, 'Different', 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
